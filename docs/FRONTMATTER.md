# Frontmatter Format Documentation

## Overview

All diary entry files now support YAML frontmatter at the beginning of the file. This frontmatter contains structured metadata about the entry, consolidating information that was previously scattered throughout the file in comments.

## Static vs Calculated Attributes

The frontmatter contains two types of fields:

1. **Static Attributes**: Manually filled by researchers/editors
2. **Calculated Attributes**: Auto-generated by scripts

After creating or updating static attributes, run:
```bash
just update-frontmatter <carnet>          # updates all entries in a carnet
just update-frontmatter-entry <filepath>  # updates single entry
```

## Implementation Status

### Completed
- ✅ Frontmatter parsing and generation utilities (`scripts/frontmatter_utils.py`)
- ✅ Parser support for reading entries with frontmatter (`scripts/paragraph_parser.py`)
- ✅ Renderer support for generating frontmatter (`scripts/paragraph_renderer.py`)
- ✅ Tool to check for orphaned comments (`scripts/check_orphaned_comments.py`)
- ✅ Test utilities (`scripts/test_frontmatter.py`)

### Current Behavior
- Files are written with `.new.md` extension to avoid overwriting originals
- File-level comments are automatically moved to frontmatter
- Paragraph-level comments remain with their paragraphs

### Known Issues to Address
- File-level notes still appear in paragraph comments (need to remove after moving to frontmatter)
- Duplicate entries in locations array need deduplication
- Word count should be more accurate (currently counts all words in file)

## Frontmatter Structure

```yaml
---
# ========== STATIC ATTRIBUTES ==========
# (manually filled by researchers/editors)

# Basic metadata
date: 1873-01-11              # ISO date (extracted from filename)
type: daily_entry              # entry type: daily_entry, merged_entry, continuation
carnet: "001"                  # 3-digit carnet number (000-105)
entry_id: "1873-01-11"         # unique identifier

# Location and context
location: Nice                 # primary location (first place mentioned)
locations: [Nice, Rome]        # all locations mentioned in entry

# Date information
dates:
  primary: "Samedi 11 janvier 1873"    # full date header from entry
  merged: []                           # for slash format entries like ["Vendredi 4", "Samedi 5"]

# Glossary entities mentioned
entities:
  people: [Howard_family, Mouton]
  places: [Nice, Promenade_des_Anglais]
  cultural: [Un_ballo_in_maschera]

# File-level notes (moved from comments)
notes:
  - "2025-12-07T16:00:00 RSR: Marie's location is Nice, France..."
  - "2025-12-07T10:00:00 LAN: Entry contains several period-specific..."

# Workflow metadata
workflow:
  research_complete: true
  linguistic_annotation_complete: true
  translation_complete: false
  editorial_review_complete: false
  conductor_approval: false
  last_modified: 2025-12-07T16:00:00
  modified_by: researcher

# Special flags
flags:
  empty_in_source: false      # true if verified empty in raw carnet
  has_continuation: false     # true if continues in next file

# ========== CALCULATED ATTRIBUTES ==========
# (auto-generated by scripts - leave empty when creating)

# Marie's age (calculated from birth date: 1860-11-24)
marie_age:
  years: 12
  months: 1
  days: 18

# Content metrics (calculated)
metrics:
  paragraph_count: 7           # count of unique paragraph IDs
  word_count: 156             # words in actual content (not comments)
  has_original: true          # has French text
  has_translation: false      # has Czech translation
  translation_version_count: 0 # number of translation versions
---
```

## Field Descriptions

### Basic Metadata
- **date**: ISO format date extracted from filename
- **type**: Entry type classification
  - `daily_entry`: Standard diary entry
  - `merged_entry`: Multiple dates merged (slash format)
  - `continuation`: Continuation from previous file
- **carnet**: Three-digit carnet identifier (000-105, matching Marie's original notebook numbering)
- **entry_id**: Unique identifier (usually same as date)

### Location Data
- **location**: Primary location mentioned (usually first)
- **locations**: Array of all locations mentioned

### Date Information
- **dates.primary**: Full date header as it appears in the entry
- **dates.merged**: For entries with slash format headers (empty days merged)

### Marie's Age
Calculated based on birth date 1860-11-24 (Marie's claimed date for consistency)
- **years, months, days**: Age breakdown at time of entry

### Content Metrics (all calculated)
- **paragraph_count**: Count of unique paragraph IDs
- **word_count**: Words in actual content (excluding comments)
- **has_original**: Whether French text is present
- **has_translation**: Whether Czech translation exists
- **translation_version_count**: Number of translation versions

### Entities
Extracted from glossary links, categorized by type:
- **people**: Names of individuals
- **places**: Locations, cities, venues
- **cultural**: Books, operas, cultural references

### Notes
File-level notes moved from comments. Format:
```
"YYYY-MM-DDTHH:MM:SS ROLE: content"
```
Roles: RSR (researcher), LAN (linguistic annotator), TR (translator), etc.

### Workflow Tracking
Boolean flags for workflow stages:
- **research_complete**: RSR phase done
- **linguistic_annotation_complete**: LAN phase done
- **translation_complete**: Translation exists
- **editorial_review_complete**: Editor reviewed
- **conductor_approval**: Final approval
- **last_modified**: Timestamp of last change
- **modified_by**: Who made last change

### Special Flags
- **empty_in_source**: Entry verified as empty in raw carnet
- **has_continuation**: Entry continues in next file

## Usage Examples

### Check for orphaned comments
```bash
python scripts/check_orphaned_comments.py check --summary
```

### Test frontmatter on single entry
```bash
python scripts/test_frontmatter.py test-entry src/_original/001/1873-01-11.md
```

### Generate .new.md files for a carnet
```bash
python scripts/test_frontmatter.py test-carnet 001 --write
```

### Export orphaned comments report
```bash
python scripts/check_orphaned_comments.py export -o report.txt
```

## Migration Process

1. **Test Phase** (Current)
   - Files written as `.new.md`
   - Original files preserved
   - Manual review of generated frontmatter

2. **Migration Phase** (Future)
   - Batch convert all entries
   - Verify frontmatter accuracy
   - Replace original files

3. **Cleanup Phase** (Future)
   - Remove file-level comments from content
   - Update all scripts to use frontmatter
   - Archive original format files

## Integration with Carnet Types

The frontmatter format is designed to work with the carnet type system:

```python
from scripts.carnet_types import get_carnet_handler, CARNET_CONFIG

# Get carnet metadata
carnet_meta = CARNET_CONFIG["001"]
handler = get_carnet_handler("001")

# Handler can validate entries with frontmatter
issues = handler.validate_entry(entry_path)
```

## Notes for Developers

- Frontmatter is always optional - parser handles files with or without it
- When present, frontmatter values override extracted values
- All calculated fields are recalculated on each render
- File-level comments should be removed from content when moved to frontmatter
- The `_metadata` attribute on DiaryEntry stores parsed frontmatter for reference